,paperID,pos_score,sent_pos,text
234,soylent-uist2010.,0.867300271987915,234,"We require a minimum of six workers in Find, three workers in Fix, and three workers in Verify."
377,soylent-uist2010.,0.8479893803596497,377,The five tasks in the left column led to a variety of request strategies.
353,soylent-uist2010.,0.7994505167007446,353,We then sent the description to Mechanical Turk and requested that five Turkers complete each request.
284,soylent-uist2010.,0.7880347371101379,284,Workers were able to blend these cuts into the sentence easily.
358,soylent-uist2010.,0.732488751411438,358,Results Users were generally successful at communicating their intention (Table III).
352,soylent-uist2010.,0.6785865426063538,352,We asked them to write a task description for their prompt using The Human Macro.
42,soylent-uist2010.,0.5528777241706848,42,"Instead of training on previous users, we ask crowd workers to solve personalized tasks on demand each time."
225,soylent-uist2010.,0.49783745408058167,225,At least 20% of the Turkers must agree on a text region.
344,soylent-uist2010.,0.47474169731140137,344,Human Macro Evaluation We were interested in understanding whether end users could instruct Mechanical Turk workers to perform openended tasks.
416,soylent-uist2010.,0.3126634955406189,416,Future work falls in three categories.
285,soylent-uist2010.,0.2795543372631073,285,"Even the most technical input texts had extraneous phrases, so Shortn was usually able to make at least one small edit of this nature in each paragraph."
361,soylent-uist2010.,0.22446377575397491,361,Example Input I gave one final glance around before descending from the barrow.
220,soylent-uist2010.,0.20527848601341248,220,grammatical errors.
348,soylent-uist2010.,0.18929815292358398,348,We recruited two sets of users: five undergraduate and graduate students in our computer science department (4 male) and five administrative associates in our department (all female).
195,soylent-uist2010.,0.16977541148662567,195,Each task now consists of a constrained edit to an area of interest.
18,soylent-uist2010.,0.16878704726696014,18,Copyright 2010 ACM 978-1-4503-0271-5/10/10....$10.00.
7,soylent-uist2010.,0.14856219291687012,7,Graphical user interfaces.
150,soylent-uist2010.,0.142757385969162,150,We draw on this experience in the sections to follow.
262,soylent-uist2010.,0.10312724858522415,262,"But in order to get people to pay for their magazine and newspaper apps, they are going to have to offer something different that readers cannot get at the newsstand or on the open Web."
299,soylent-uist2010.,0.08833258599042892,299,Combining Word and Shortn caught 24 of the 37 errors.
199,soylent-uist2010.,0.08263631165027618,199,The Verify stage performs quality control on revisions.
239,soylent-uist2010.,0.061540838330984116,239,Backend scripts use the TurKit Mechanical Turk toolkit [16].
313,soylent-uist2010.,0.05514894798398018,313,Probably unrealistic.
357,soylent-uist2010.,0.03647707402706146,357,"If the Turker completed the task but made a small error, the result was coded as good intention and poor accuracy."
177,soylent-uist2010.,0.030051464214920998,177,Both the Lazy Turker and the Eager Beaver are looking for a way to clearly signal to the requester that they have completed the work.
233,soylent-uist2010.,0.028794530779123306,233,"To keep the algorithm responsive, we use a 15-minute timeout at each stage."
246,soylent-uist2010.,0.026674000546336174,246,"We required 6–10 workers to complete the Find tasks and 3–5 workers to complete the Fix and Verify tasks: if a Find task failed to recruit even six workers, it might wait indefinitely."
210,soylent-uist2010.,0.026291174814105034,210,The Verify stage reduces noise in the returned result.
298,soylent-uist2010.,0.02144377864897251,298,Microsoft Word's grammar checker caught 13 of the errors.
211,soylent-uist2010.,0.020529981702566147,211,"Anecdotally, Turkers are better at vetting suggestions than they are at producing original work."
237,soylent-uist2010.,0.018803559243679047,237,IMPLEMENTATION Soylent consists of a front-end application-level add-in to Microsoft Word and a back-end service to run Mechanical Turk tasks (Figure 4).
111,soylent-uist2010.,0.017785629257559776,111,Removing whole arguments or sections is left to the user.
215,soylent-uist2010.,0.015966804698109627,215,"Rather than wait for ten Turkers to complete the Find task before moving on to Fix, a timeout parameter can force our algorithm to advance if a minimum threshold of workers have completed the work."
137,soylent-uist2010.,0.01437719352543354,137,"The form suggests that the user provide an example input and output, which is an effective way to clarify the task requirements to workers."
19,soylent-uist2010.,0.013778203167021275,19,answer ourselves [8]; masses of volunteer editors flag spam edits on Wikipedia [13].
410,soylent-uist2010.,0.01226089522242546,410,We also may effectively personalize by directing tasks to Turkers who have successfully worked on a user's documents before.
224,soylent-uist2010.,0.012157767079770565,224,The Find stage asks ten Turkers to identify candidate areas for shortening in each paragraph.
174,soylent-uist2010.,0.011128488928079605,174,"In their zeal, this worker rendered the resulting sentence ungrammatical."
383,soylent-uist2010.,0.010897879488766193,383,(The average accuracy was 70.8%.)
384,soylent-uist2010.,0.00964926928281784,384,"Turkers commonly got the task mostly correct, but failed on some detail."
101,soylent-uist2010.,0.008754783309996128,101,"In response, Soylent launches a series of Mechanical Turk tasks in the background and notifies the user when the text is ready."
350,soylent-uist2010.,0.008333591744303703,350,We purposefully did not describe the task to the participants so that we would not influence how they wrote their task descriptions.
70,soylent-uist2010.,0.006884755566716194,70,"Recently, Ross et al."
375,soylent-uist2010.,0.006772779393941164,375,This paragraph needs an objective I feel like.
168,soylent-uist2010.,0.006633573677390814,168,Kittur et al.
75,soylent-uist2010.,0.006633573677390814,75,Little et al.
114,soylent-uist2010.,0.006236928049474955,114,"The process finds errors, explains the problem, and offers one to five alternative rewrites."
351,soylent-uist2010.,0.005035751964896917,351,We then introduced participants to The Human Macro and described what it would do.
134,soylent-uist2010.,0.005028317682445049,134,We wish to prevent the user from spending money on a buggy command.
345,soylent-uist2010.,0.004850681405514479,345,Can users communicate their intention clearly?
318,soylent-uist2010.,0.004824195522814989,318,"According to believers, ""Dandu Monara"" landed at Werangatota."
307,soylent-uist2010.,0.0048057627864181995,307,You Kknow Wwhat I am Ssaying.
45,soylent-uist2010.,0.004700346849858761,45,"We then introduce Soylent and its main components: Shortn, Crowdproof, and The Human Macro."
386,soylent-uist2010.,0.004316202364861965,386,"These kinds of errors would be dangerous to expose to the user, because the user might likewise not realize that there is a small error in the work."
62,soylent-uist2010.,0.0039939964190125465,62,'s PEST [23] uses Mechanical Turk to vet advertisement recommendations.
15,soylent-uist2010.,0.003962937276810408,15,We ask friends to answer questions that we cannot Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
396,soylent-uist2010.,0.0039022848941385746,396,"We counter that in fact all current document processing tasks also incur significant cost (in terms of computing infrastructure, time, software and salaries); the only difference is that interface outsourcing precisely quantifies the price of each small unit of work."
373,soylent-uist2010.,0.0035678488202393055,373,Don't you feel a bit lonely? [...]
194,soylent-uist2010.,0.003555042203515768,194,The Fix stage recruits workers to revise a patch.
301,soylent-uist2010.,0.0035025638062506914,301,It continued to produce cuts between 70–80% with each iteration.
267,soylent-uist2010.,0.003265819512307644,267,"$9.72 362 workers 44 – 52 min A previous board member, Steve Burleigh, created our web site last year and gave me alot of ideas."
223,soylent-uist2010.,0.0031367328483611345,223,We begin by splitting the input region into paragraphs.
346,soylent-uist2010.,0.0029604861047118902,346,Can Turkers execute the amateur-authored tasks correctly?
37,soylent-uist2010.,0.002931356430053711,37,Find-Fix-Verify splits complex crowd intelligence tasks into a series of generation and review stages that utilize independent agreement and voting to produce reliable results.
200,soylent-uist2010.,0.0029202336445450783,200,We randomize the order of the unique alternatives generated in the Fix stage and ask 3–5 new workers to vote on them (Figure 4).
193,soylent-uist2010.,0.0025629771407693624,193,These are then fed in parallel into the Fix stage.
403,soylent-uist2010.,0.002535807667300105,403,Do the Turkers who participate in Find-Fix-Verify gain any legal rights to the document?
185,soylent-uist2010.,0.002410127315670252,185,"In this section, we propose the Find-Fix-Verify pattern as one method of programming crowds to reliably complete open-ended tasks that directly edit the user's data."
414,soylent-uist2010.,0.002320162020623684,414,"We have introduced one important pattern, FindFix-Verify, which splits complex editing tasks into a series of identification, generation, and verification stages that use independent agreement and voting to produce reliable results."
76,soylent-uist2010.,0.00228204601444304,76,advocate the use of human computation algorithms on Mechanical Turk [16].
316,soylent-uist2010.,0.0020764428190886974,316,The King Ravana (Sri Lanka) built it.
222,soylent-uist2010.,0.002039396669715643,222,"Find-Fix-Verify identifies patches in need of editing, recruits workers to fix the patches, and votes to approve work."
189,soylent-uist2010.,0.002036948688328266,189,"For example, when proofreading, the Find stage asks for at least one phrase or sentence that needs editing (Figure 4)."
370,soylent-uist2010.,0.0020050762686878443,370,"include all When I first visited Yosemite State Park in California, I was a boy."
78,soylent-uist2010.,0.0019781736191362143,78,"It is specifically intended to control lazy and overeager Turkers, identify which edits are tied to the same problem, and visualize them in an interface."
272,soylent-uist2010.,0.0019249336328357458,272,The Example Output column contains example edits from each input.
295,soylent-uist2010.,0.0018284489633515477,295,"To investigate the extent of these issues, we coded all 126 shortening suggestions as to whether they led to a grammatical error."
125,soylent-uist2010.,0.001801105448976159,125,"If the user hovers over the Error Descriptions menu item, the popout menu suggests additional second-opinions of why the error was called out."
328,soylent-uist2010.,0.0017536211526021361,328,"Combined, Word and Soylent flagged 82% of all errors."
286,soylent-uist2010.,0.0016906668897718191,286,Shortn occasionally introduced errors into the paragraph.
282,soylent-uist2010.,0.001575977192260325,282,"Qualitatively, Shortn was most successful when the input had unnecessary text."
202,soylent-uist2010.,0.0015511689707636833,202,"To ensure that Turkers cannot vote for their own work, we ban all Fix workers from participating in the Verify stage."
245,soylent-uist2010.,0.0015073305694386363,245,"To simulate a real-world deployment, we ran the algorithms with a timeout enabled and set to twenty minutes."
192,soylent-uist2010.,0.001462173298932612,192,"the interface needs a default choice, Soylent keeps patches where at least 20% of the workers agree."
151,soylent-uist2010.,0.001454238430596888,151,Challenges in Programming with Crowd Workers We are primarily concerned with tasks where workers directly edit a user's data in an open-ended manner.
305,soylent-uist2010.,0.00143029959872365,305,"We manually labeled all spelling, grammatical and style errors in each of the five inputs, identifying a total of 49 errors."
132,soylent-uist2010.,0.0014060946414247155,132,Launching the Human Macro opens a request form (Figure 3).
124,soylent-uist2010.,0.0013458257308229804,124,"By clicking on the desired alternative, the user replaces the incorrect text with an option of his or her choice."
413,soylent-uist2010.,0.0013393510598689318,413,"Implementing these kinds of interfaces requires new software programming patterns for interface software, since crowds behave differently than computer systems."
102,soylent-uist2010.,0.0013333316892385483,102,The user can then launch the Shortn dialog box (Figure 1).
216,soylent-uist2010.,0.0012922785244882107,216,Find-Fix-Verify in Soylent Both Shortn and Crowdproof use the Find-Fix-Verify pattern.
89,soylent-uist2010.,0.001269958564080298,89,"Shortn's approach, which can rewrite or cut parts of sentences, is an example of sentence compression, an area of active recent research [5, 12] that suffers from a lack of training data [4]."
242,soylent-uist2010.,0.001223836443386972,242,"Our goal was to see how much Shortn could shorten text, as well as its associated cost and time characteristics."
129,soylent-uist2010.,0.0012168367393314838,129,"While natural language command interfaces continue to struggle with unconstrained input over a large search space, humans are good at understanding written instructions."
99,soylent-uist2010.,0.0012015447719022632,99,Soylent's Shortn interface allows authors to condense sections of text.
268,soylent-uist2010.,0.0011263020569458604,268,"For this year, I found a web site called eTeamZ that hosts web sites for sports groups."
138,soylent-uist2010.,0.0010915815364569426,138,"If the user selected text before opening the dialog, he has the option to split the task by each sentence or paragraph, so (for example) the task might be parallelized across all entries on a list."
26,soylent-uist2010.,0.0010867281816899776,26,Soylent aids the writing process by integrating paid crowd workers from Amazon's Mechanical Turk platform1 into Microsoft Word.
409,soylent-uist2010.,0.0010323208989575505,409,"However, a large subset of editing tasks only requires generic editing skills."
325,soylent-uist2010.,0.0009924274636432528,325,We ruled that Crowdproof had caught an error if one of the identified patches contained the error.
389,soylent-uist2010.,0.0009801897685974836,389,"We touch on resulting issues of wait time, cost, legal ownership, privacy, and domain knowledge."
140,soylent-uist2010.,0.0009783734567463398,140,The Human Macro helps debug the task by allowing a test run on one sentence or paragraph.
250,soylent-uist2010.,0.000973410380538553,250,"In all tasks, it was possible for the algorithm to stall while waiting for workers, having a large effect on averages."
392,soylent-uist2010.,0.0009616045863367617,392,"While future growth in crowdsourced work will likely shorten lag times, this is an important avenue of future work."
217,soylent-uist2010.,0.0009597586467862129,217,We will use Shortn as an illustrative example.
382,soylent-uist2010.,0.0009531239629723132,382,"With accuracy, we again see that roughly 30% of work contained an error."
107,soylent-uist2010.,0.0009308554581366479,107,Areas of text that have been edited or removed are highlighted in red in the visualization.
115,soylent-uist2010.,0.0009247191483154893,115,Crowdproof is essentially a distributed proofreader operating for cents per task.
71,soylent-uist2010.,0.0009120635222643614,71,"found that Mechanical Turk had two major populations: well-educated, moderate-income Americans, and young, well-educated but less wealthy workers from India [22]."
83,soylent-uist2010.,0.0009025222971104085,83,Shortn allows users to adjust the length of a paragraph via a slider.
187,soylent-uist2010.,0.0008987619658000767,187,Find-Fix-Verify The Find-Fix-Verify pattern separates open-ended tasks into three stages where workers can make clear contributions.
251,soylent-uist2010.,0.0008604357717558742,251,"Therefore, we report medians, which are more robust to outliers."
172,soylent-uist2010.,0.0008555848617106676,172,"Eager Beavers go beyond the task requirements in order to be helpful, but create further work for the user in the process."
208,soylent-uist2010.,0.000852661207318306,208,"Had each Turker edited the entire paragraph, we would not know which edits were trying to fix the same problem."
336,soylent-uist2010.,0.000835011771414429,336,Crowdproof's most common problem was missing a minor error that was in the same patch as a more egregious error.
176,soylent-uist2010.,0.0008249867823906243,176,It would be problematic to funnel such work back to the user.
23,soylent-uist2010.,0.0008245304343290627,23,We hypothesize that crowd workers with a basic knowledge of written English can support both novice and expert writers.
393,soylent-uist2010.,0.000808088225312531,393,"It may be possible to explicitly engineer for responsiveness in return for higher monetary investment, or to keep workers on retainer with distractor tasks until needed [3]."
167,soylent-uist2010.,0.0007998659857548773,167,A first challenge is thus to discourage or prevent workers from such behavior.
74,soylent-uist2010.,0.0007925753016024828,74,"Heer and Bostock explored Mechanical Turk as a testbed for graphical perception experiments, finding reliable results when they implemented basic measures like qualification tests [10]."
331,soylent-uist2010.,0.0007907709805294871,331,Crowdproof was effective at fixing errors that it found.
120,soylent-uist2010.,0.000789655081462115,120,Crowdproof is a human-augmented proofreader.
66,soylent-uist2010.,0.0007878129836171865,66,Standard Minds backed by Mechanical Turk that accepts plain text via a web form and returns edits one day later.
156,soylent-uist2010.,0.0007797721191309392,156,"Clearly, a 30% error rate is unacceptable to the end user."
278,soylent-uist2010.,0.0007773363613523543,278,The average paragraph cost $1.41 to shorten under our pay model.
130,soylent-uist2010.,0.0007715884130448103,130,The Human Macro is Soylent's natural language command interface.
372,soylent-uist2010.,0.0007711643702350557,372,"Think about how you launch programs, edit documents, and browse the web."
252,soylent-uist2010.,0.0007480655913241208,252,Results Shortn produced revisions that were 78%–90% of the original document length.
390,soylent-uist2010.,0.0007400432368740439,390,"In our vision of interface outsourcing, authors have immediate access to a pool of human expertise."
179,soylent-uist2010.,0.0007400114554911852,179,Turkers Introduce Errors Turkers working on complex tasks can accidentally introduce substantial new errors.
139,soylent-uist2010.,0.0007367076468653977,139,The user then chooses how many separate Turkers he would like to complete the task.
96,soylent-uist2010.,0.0007351795793510973,96,Other writers write overly wordy prose and need help editing.
275,soylent-uist2010.,0.0007246510358527303,275,We estimate overall work time by examining the median amount of time a worker spent in each stage of the Find-Fix-Verify process.
131,soylent-uist2010.,0.000701805402059108,131,Soylent users can use it to request arbitrary work quickly in human language.
241,soylent-uist2010.,0.00069467443972826,241,Shortn Evaluation We evaluated Shortn quantitatively by running it on example texts.
310,soylent-uist2010.,0.0006905364571139216,310,"However, while GUI made using computers be more intuitive and easier to learn, it didn't let people be able to control computers efficiently."
258,soylent-uist2010.,0.000656682183034718,258,"The vast majority of Shortn's running time is currently spent waiting, because it can take minutes or hours for Turkers to find and accept the task."
57,soylent-uist2010.,0.0006528249359689653,57,Google Suggest mines query logs to speed and direct new queries.
27,soylent-uist2010.,0.0006482626195065677,27,Soylent is people: its core algorithms involve calls to Mechanical Turk workers (Turkers).
391,soylent-uist2010.,0.0006455970578826964,391,"Lag times in our current implementation are still on the order of minutes to hours, due to worker demographics, worker availability, the relative attractiveness of our tasks, and so on."
146,soylent-uist2010.,0.0006429150234907866,146,comment bubbles anchored on the selected text by utilizing Word's reviewing comments interface.
277,soylent-uist2010.,0.0006286227144300938,277,"As Mechanical Turk grows, users may see shortening tasks approaching a limit of two minutes."
164,soylent-uist2010.,0.0006267233402468264,164,In my mind for a theme to be pervasive is must be present during every element of the story.
2,soylent-uist2010.,0.0006180877098813653,2,"Authoring tools offer help with pragmatics, but for higher-level help, writers commonly turn to other people."
213,soylent-uist2010.,0.0006161598139442503,213,Verification trades off time lag with quality: a user who can tolerate more error but needs less time lag might opt not to verify work or use fewer verification workers.
64,soylent-uist2010.,0.0006156151066534221,64,"Soylent extends this work to more creative, complex tasks where the user can make personalized requests and interact with the returned data by direct manipulation."
170,soylent-uist2010.,0.000614382151979953,170,that forced the Lazy Turker to read the material being studied.
58,soylent-uist2010.,0.0006124602514319122,58,"Soylent is unique in asking paid crowd workers to solve the user's problems, rather than aggregating past activity."
46,soylent-uist2010.,0.0005920998519286513,46,We detail the Find-Fix-Verify pattern that powers Soylent; evaluate the feasibility of our three components; and conclude with a discussion of privacy issues and inherent limitations of our approach.
334,soylent-uist2010.,0.0005837669013999403,334,"Fully 28 of 62 suggestions, or 45%, were ungrammatical."
148,soylent-uist2010.,0.0005792488809674978,148,We introduce the Find-Fix-Verify pattern to improve output quality in the face of uncertain worker quality.
186,soylent-uist2010.,0.000578594277612865,186,We describe the pattern and then explain its use in Soylent.
51,soylent-uist2010.,0.0005755963502451777,51,"Soylent tackles problems that are currently infeasible for AI algorithms, even with abundant data."
73,soylent-uist2010.,0.0005753482109867036,73,Find-FixVerify builds on this notion of requiring verification to control quality.
362,soylent-uist2010.,0.0005746926763094962,362,"As I did so, my eye caught something [...] Example Output I give one final glance around before descending from the barrow."
270,soylent-uist2010.,0.0005731732817366719,270,FAWN-DS extracts two fields from the 160-bit key: the i low order bits of the key (the index bits) and the next 15 low order bits (the key fragment).
162,soylent-uist2010.,0.0005582654848694801,162,The change is highlighted: The theme of loneliness features throughout many scenes in Of Mice and Men and is often the dominant theme of sections during this story.
14,soylent-uist2010.,0.0005370475701056421,14,"In our everyday life, when we need help with complex cognition and manipulation tasks, we often turn to other people."
0,soylent-uist2010.,0.0005333475419320166,0,"Soylent: A Word Processor with a Crowd Inside Björn Hartmann2, Mark S. Ackerman3, David R. Karger1, David Crowell1, Katrina Panovich1 Michael S. Bernstein1, Greg Little1, Robert C. Miller1, 1 MIT CSAIL Cambridge, MA {msbernst, glittle, rcm, karger, dcrowell, kp}@csail.mit.edu 2 Computer Science Division University of California, Berkeley Berkeley, CA bjoern@cs.berkeley.edu 3 Computer Science & Engineering University of Michigan Ann Arbor, MI ackerm@umich.edu ABSTRACT This paper introduces architectural and interaction patterns for integrating crowdsourced human contributions directly into user interfaces."
60,soylent-uist2010.,0.0005295292939990759,60,Soylent builds on work embedding on-demand workforces inside applications and services.
292,soylent-uist2010.,0.0005280654295347631,292,Modern auto-correction techniques could catch many of these errors.
112,soylent-uist2010.,0.0005239294259808958,112,"Crowdproof: Crowdsourced Proofreading Soylent provides a human-aided spelling, grammar and style checking interface called Crowdproof (Figure 2)."
231,soylent-uist2010.,0.0005218457081355155,231,We use majority voting to remove problematic rewrites and to decide if the patch can be removed.
1,soylent-uist2010.,0.0005110844504088163,1,"We focus on writing and editing, complex endeavors that span many levels of conceptual and pragmatic activity."
91,soylent-uist2010.,0.0004984038532711565,91,"Several systems allow users to demonstrate repetitive editing tasks for automatic execution; examples include Eager, TELS, and Cima [6], LAPIS [20], and SmartEdit [15]."
158,soylent-uist2010.,0.0004903491935692728,158,High Variance of Effort Turkers exhibit high variance in the amount of effort they invest in a task.
182,soylent-uist2010.,0.0004898094921372831,182,The Find-Fix-Verify Pattern Our crowdsourced interface algorithms must control the efforts of both the Eager Beaver and Lazy Turker and limit introduction of errors.
240,soylent-uist2010.,0.00048775208415463567,240,"EVALUATION Our initial evaluation sought to establish evidence for Soylent's end-to-end feasibility, as well as to understand the properties of the Find-Fix-Verify design pattern."
236,soylent-uist2010.,0.0004848437965847552,236,This search is a special case of the knapsack problem and can be solved with a polynomial time dynamic programming algorithm.
197,soylent-uist2010.,0.0004706719482783228,197,A small number (3–5) of workers propose revisions.
388,soylent-uist2010.,0.00046984959044493735,388,"Our work suggests that it may be possible to transition from an era where Wizard of Oz techniques were used only as prototyping tools to an era where a ""Wizard of Turk"" can be permanently wired into a system."
214,soylent-uist2010.,0.00046480612945742905,214,One challenge that the Find-Fix-Verify pattern shares with other Mechanical Turk algorithms is that it can stall when workers are slow to accept the task.
6,soylent-uist2010.,0.0004591444740071893,6,ACM Classification: H5.2 [Information interfaces and presentation]: User Interfaces. -
79,soylent-uist2010.,0.00045227661030367017,79,Quinn and Bederson have authored a survey of human computation systems that expands on this brief review [21].
34,soylent-uist2010.,0.0004508507845457643,34,"We expand these contri- 1 http://www.mturk.com butions with feasibility studies of the performance, cost, and time delay of our three main components and a discussion of the limitations of our approach with respect to privacy, delay, cost, and domain knowledge."
173,soylent-uist2010.,0.00043644438846968114,173,"For example, when asked to reword a phrase, one Eager Beaver provided a litany of options: The theme of loneliness features throughout many scenes in Of Mice and Men and is often the principal, significant, primary, preeminent, prevailing, foremost, essential, crucial, vital, critical theme of sections during this story."
266,soylent-uist2010.,0.00043355298112146556,266,"We present WenSo, a tool thatwhich uses lightweight text input to capture richly structured information for later retrieval and navigation in a graphical environment."
274,soylent-uist2010.,0.00042900079279206693,274,"Considering only work time and assuming negligible wait time, Shortn produced cuts within minutes."
55,soylent-uist2010.,0.00040046506910584867,55,FeedMe [1] and Collabio [2] use friends to power recommender systems and tag cloud visualizations.
322,soylent-uist2010.,0.0004003990034107119,322,A report on Crowdproof's runtime characteristics and example output.
257,soylent-uist2010.,0.00039609099621884525,257,"To investigate time characteristics, we separate the notion of wait time from work time."
398,soylent-uist2010.,0.00039043903234414756,398,"Regarding privacy, Soylent exposes the author's document to third party workers without knowing the workers' identities."
254,soylent-uist2010.,0.0003875363618135452,254,Table I summarizes and gives examples of Shortn's behavior.
87,soylent-uist2010.,0.00037576924660243094,87,"Soylent's Shortn component is related to document summarization, which has also received substantial research attention [18]."
155,soylent-uist2010.,0.0003714002959895879,155,"This ""30% rule"" is supported by the experimental section of this paper as well."
28,soylent-uist2010.,0.0003641723014879972,28,"Soylent is comprised of three main components: 1) Shortn, a text shortening service that cuts selected text down to 85% of its original length typically without changing the meaning of the text or introducing errors."
143,soylent-uist2010.,0.00036307782283984125,143,"If the user chooses to annotate, the feedback populates Figure 3."
364,soylent-uist2010.,0.0003593384462874383,364,"Go to a site which hsa CC licensed images [...]"" CS: ""Please tell me how to make this paragraph communicate better."
160,soylent-uist2010.,0.00035867231781594455,160,The Lazy Turker does as little work as necessary to get paid.
207,soylent-uist2010.,0.00035066803684458137,207,"Additionally, splitting Find and Fix enables us to merge work completed in parallel."
147,soylent-uist2010.,0.0003494748962111771,147,TECHNIQUES FOR PROGRAMMING CROWDS This section characterizes the challenges of leveraging crowd labor for open-ended document editing tasks.
183,soylent-uist2010.,0.0003330402832943946,183,"Absent suitable control techniques, the rate of problematic edits is too high to be useful."
349,soylent-uist2010.,0.000314259814331308,349,"We showed each user one of the five prompts, consisting of an example input and output pair."
333,soylent-uist2010.,0.00031291061895899475,333,"To investigate the impact of the Verify stage, we labeled each unique correction that Turkers suggested as grammatical or not."
43,soylent-uist2010.,0.000304908724501729,43,This interface-for-hire model has benefits and limitations that we explore in this paper.
157,soylent-uist2010.,0.00030384535784833133,157,"To address the problem, it is important to understand the nature of unsatisfactory responses."
33,soylent-uist2010.,0.0003026606282219291,33,"This paper contributes the design of one such system, an implementation embedded in Microsoft Word, and a programming pattern that increases the reliability of paid crowd workers on complex tasks."
65,soylent-uist2010.,0.00029910559533163905,65,Proofreading is emerging as a common task on Mechanical offers a proofreading service Turk.
22,soylent-uist2010.,0.00029563443968072534,22,"As a step toward integrating this human expertise permanently into our writing tools, we present Soylent, a word processing interface that utilizes crowd contributions to aid complex writing tasks ranging from error prevention and paragraph shortening to automation of tasks like citation searches and tense changes."
340,soylent-uist2010.,0.0002946086460724473,340,Crowdproof shared many running characteristics with Shortn.
93,soylent-uist2010.,0.0002883877605199814,93,"SOYLENT Soylent is a prototype crowdsourced word processing interface with three features: shortening, proofreading, and arbitrary macro tasks via human-language input."
69,soylent-uist2010.,0.0002858519437722862,69,Soylent's usage of human computation means that its behavior depends in large part on qualities of crowdsourcing systems and Mechanical Turk in particular.
67,soylent-uist2010.,0.000285000482108444,67,"By contrast, Soylent is embedded in a word processor, has much lower latency, and presents the edits in Microsoft Word's user interface."
50,soylent-uist2010.,0.00027276872424408793,50,Mechanical Turk is already used to collect labeled data for machine vision [26] and natural language processing [25].
133,soylent-uist2010.,0.0002710940025281161,133,The design challenge here is to ensure that the user creates tasks that are scoped correctly for a Mechanical Turk worker.
128,soylent-uist2010.,0.00026896008057519794,128,But tasks conveyed to humans can be written in a much more natural way.
188,soylent-uist2010.,0.00026698922738432884,188,"The first stage, Find, asks Turkers to identify patches of the user's work that need more attention."
88,soylent-uist2010.,0.0002621633466333151,88,"Microsoft Word has a summarization feature that uses sentence extraction, which identifies whole sentences to preserve in a passage and deletes the rest, producing substantial shortening but at a great cost in content."
261,soylent-uist2010.,0.00024957736604847014,261,"So, while our current median total wait time summed across the three stages was 18.5 minutes (1st Quartile Q1 = 8.3 minutes, 3rd Quartile Q3 = 41.6 minutes), we believe that in Input Blog Classic UIST [28] Draft UIST [29] Rambling E-mail Highly Technical Writing [3] Original Length 3 paragraphs 12 sentences 272 words 7 paragraphs 22 sentences 478 words 5 paragraphs 23 sentences 652 words 6 paragraphs 24 sentences 406 words 3 paragraphs 13 sentences 291 words 87% 90% 78% 82% Final Length 83% character length Turk Statistics $4.57 158 workers Time per Paragraph 46 – 57 min $7.45 264 workers 49 – 84 min $7.47 284 workers 52 – 72 min Example Output Print publishers are in a tizzy over Apple's new iPad because they hope to finally be able to charge for their digital editions."
327,soylent-uist2010.,0.0002491344348527491,327,"For comparison, Microsoft Word's grammar checker found 15 errors (30%)."
315,soylent-uist2010.,0.00023932238400448114,315,"Dandu Monara (Flying Peacock, Wooden Peacock), The Flying mMachine able to fly."
8,soylent-uist2010.,0.00023843043891247362,8,"General terms: Design, Human Factors Keywords: Outsourcing, Mechanical Turk, Crowdsourcing INTRODUCTION Word processing is a complex task that touches on many goals of human-computer interaction."
232,soylent-uist2010.,0.000238041378906928,232,"At the end of the Verify stage, we have a set of candidate patches and a list of verified rewrites for each patch."
243,soylent-uist2010.,0.00023788114776834846,243,"We collected five examples of texts that might be sent to Shortn, each between one and seven paragraphs long."
337,soylent-uist2010.,0.00023493297339882702,337,The four errors that Crowdproof failed to fix were all contained in patches with at least one other error; Lazy Turkers fixed only the most noticeable problem.
203,soylent-uist2010.,0.00022818542493041605,203,Pattern Discussion Why should tasks be split into independent Find-Fix-Verify stages?
63,soylent-uist2010.,0.00022740861459169537,63,These systems consist of a single user operation and little or no interaction.
253,soylent-uist2010.,0.00022730306955054402,253,"For reference, a reduction to 85% could slim an 113⁄4 page UIST draft down to 10 pages with no substantial cuts in the content."
77,soylent-uist2010.,0.00022163447283674031,77,Find-Fix-Verify may be viewed as a new design pattern for human computation algorithms.
3,soylent-uist2010.,0.00022127717966213822,3,"We thus present Soylent, a word processing interface that enables writers to call on Mechanical Turk workers to shorten, proofread, and otherwise edit parts of their documents on demand."
381,soylent-uist2010.,0.0002205133787356317,381,Successful users clearly signaled Creative Commons status in the title field of their request.
263,soylent-uist2010.,0.00021846230083610862,263,The metaDESK effort is part of the larger Tangible Bits project.
385,soylent-uist2010.,0.00021844482398591936,385,"For example, in the Tense task, some Turkers changed all but one of the verbs to present tense, and in the List Processing task, sometimes a field would not be correctly capitalized or an Eager Beaver would add too much extra information."
356,soylent-uist2010.,0.00021557607396971434,356,and accuracy (was the result flawless?).
378,soylent-uist2010.,0.0002112229267368093,378,"Terse, error-filled user requests still often led to success."
368,soylent-uist2010.,0.000210667509236373,368,"You can located these by Google Scholar searches and clicking on bibtex."""
244,soylent-uist2010.,0.00021015004313085228,244,We chose these inputs to span from preliminary drafts to finished essays and from easily understood to dense technical material (Table I).
411,soylent-uist2010.,0.0002088665060000494,411,"CONCLUSION The following conclusion was Shortn'ed to 85% length: This paper presents Soylent, a word processing interface that uses crowd workers to help with proofreading, document shortening, editing and commenting tasks."
49,soylent-uist2010.,0.00020529176981654018,49,"For example, the ESP Game [27] collects descriptions of objects in images for use in object recognition."
4,soylent-uist2010.,0.00020511832553893328,4,"To improve worker quality, we introduce the Find-Fix-Verify crowd programming pattern, which splits tasks into a series of generation and review stages."
141,soylent-uist2010.,0.00019937625620514154,141,The user chooses whether the Turkers' work should replace the existing text or just annotate it.
154,soylent-uist2010.,0.00019511819118633866,154,"As a rule-of-thumb, roughly 30% of the results from open-ended tasks are poor."
400,soylent-uist2010.,0.00019480788614600897,400,"One solution is to restrict the set of workers that can perform tasks: for example, large companies could maintain internal worker pools."
354,soylent-uist2010.,0.0001939594658324495,354,"In addition to the ten requests generated by our participants, one author generated five requests himself to simulate a user who is familiar with Mechanical Turk."
367,soylent-uist2010.,0.0001937423658091575,367,"Admin: ""Hi, please find the bibtex references for the 3 papers in brackets."
335,soylent-uist2010.,0.0001929234858835116,335,The fact that such noisy suggestions produced correct replacements again suggests that Turkers are much better at verification than they are at authoring.
290,soylent-uist2010.,0.00018730571900960058,290,"Cuts were a second source of error: Turkers in the Fix stage would vote that a patch could be removed entirely from the sentence, but were not given the chance to massage the cut into the sentence."
184,soylent-uist2010.,0.0001820558391045779,184,"We feel that the state of programming crowds is analogous to that of UI technology before the introduction of design patterns like Model-View-Controller, which codified best practices."
394,soylent-uist2010.,0.00017467295401729643,394,"With respect to cost, Soylent requires that authors pay all workers for document editing — even if many changes never find their way into the final work product."
347,soylent-uist2010.,0.00017256282444577664,347,Method We generated five feasible Human Macro scenarios (Table III).
142,soylent-uist2010.,0.00016962252266239375,142,"If the user chooses to replace, the Human Macro underlines the text in purple and enables drop-down substitution like the Crowdproof interface."
312,soylent-uist2010.,0.00016716468962840736,312,"Blah blah blah—This is an argument about whether there should be a standard ""nosql NoSQL storage"" API to protect developers storing their stuff in proprietary services in the cloud."
105,soylent-uist2010.,0.00016702947323210537,105,"As the user does so, Shortn computes the combination of crowd trimmings that most closely match the desired length and presents that text to the user on the right."
126,soylent-uist2010.,0.00016482402861583978,126,The Human Macro: Natural Language Crowd Scripting Embedding crowd workers in an interface allows us to reconsider designs for short end-user programming tasks.
36,soylent-uist2010.,0.00016420688189100474,36,"Mechanical Turk costs money and it can be error-prone; to be worthwhile to the user, we must control costs and ensure correctness."
302,soylent-uist2010.,0.00016292200598400086,302,"We ceased after 3 iterations, having shortened the text to less than 50% length without sacrificing readability or major content."
264,soylent-uist2010.,0.00016278175462502986,264,"The Tangible Bits vision paper, which introduced the metaDESK along withand two companion platforms, the transBOARD and ambientROOM."
405,soylent-uist2010.,0.00016126774426084012,405,Likewise with historical precedent: traditional copyeditors do not own their edits to an article.
306,soylent-uist2010.,0.00016070112178567797,306,We then ran Input Passes Word's Checker 4 ESL Notes Wikipedia UIST Draft Content 1 paragraph 4 sentences 49 words 1 paragraph 8 sentences 166 words 2 paragraphs 8 sentences 107 words 1 paragraph 5 sentences 63 words 1 paragraph 6 sentences 135 words Errors all/caught/fixed 9 / 9 / 8 12 / 5 / 4 14 / 8 / 8 Turkers $4.76 77 workers $2.26 38 workers $4.72 79 workers 47 min 42–53 min 8 / 7 / 6 $2.18 36 workers 54 min Example Output Time 48 min Marketing areis bad for brands big and small.
371,soylent-uist2010.,0.00015824618458282202,371,I was amazed by how big everything was [...] http://commons.wikimedia.org /wiki/File:03_yosemite_half_dome.jpg Take a look at your computer.
95,soylent-uist2010.,0.00015717405767645687,95,This is painful work and a questionable use of the authors' time.
406,soylent-uist2010.,0.00014262969489209354,406,"However, crowdsourced interfaces will need to consider legal questions carefully."
98,soylent-uist2010.,0.00013614432828035206,98,"Additionally, they cannot use language generation techniques to make sure the resulting text flows."
204,soylent-uist2010.,0.0001303702883888036,204,"Why not let Turkers find an error and fix it, for increased efficiency and economy?"
104,soylent-uist2010.,0.00012961078027728945,104,Shortn provides a single slider to allow the user to continuously adjust the length of the paragraph.
117,soylent-uist2010.,0.000123840436572209,117,The task is queued to the Soylent status pane and the user is free to keep working.
291,soylent-uist2010.,0.00012109417002648115,291,"So, cuts often led to capitalization and punctuation problems at sentence boundaries."
32,soylent-uist2010.,0.00011988534242846072,32,These crowd workers do tasks that computers cannot reliably do automatically and the user cannot easily script.
127,soylent-uist2010.,0.00011878032091772184,127,"Typically, users need to translate their intentions into algorithmic thinking explicitly via a scripting language or implicitly through learned activity [6]."
17,soylent-uist2010.,0.00011835062468890101,17,"UIST'10, October 3–6, 2010, New York, New York, USA."
72,soylent-uist2010.,0.00011804403038695455,72,"Kittur and Chi considered how to run user studies on Mechanical Turk, proposing the use of quantitative verifiable questions as a verification mechanism [11]."
309,soylent-uist2010.,0.00011737651948351413,309,Updating of brand image areis bad for processes in one company and many companies.
82,soylent-uist2010.,0.00011719476606231183,82,"Its grammar checker suffers from the opposite problem: it misses blatant errors.4 Human checkers are currently more reliable, and can also offer suggestions on how to fix the errors they find, which is not always possible 2 http://www.chacha.com 3 http://www.standardminds.com 4 http://faculty.washington.edu/sandeep/check Figure 1."
380,soylent-uist2010.,0.00011624310718616471,380,"Turkers read far enough to understand that they needed to find a picture, found one, and left."
106,soylent-uist2010.,0.00011514215293573216,106,"From the user's point of view, as she moves the slider to make the paragraph shorter, sentences are slightly edited, combined and cut completely to match the length requirement."
123,soylent-uist2010.,0.0001129922311520204,123,"If the user clicks on the error, a drop-down menu explains the problem and offers a list of alternatives."
341,soylent-uist2010.,0.0001111143792513758,341,"Its median work time was 2.8 minutes (Q1 = 1.7 minutes, Q3 = 4.7 minutes), so it completes in very little work time."
31,soylent-uist2010.,0.00010927535913651809,31,The main contribution of this paper is the idea of embedding paid crowd workers in an interactive user interface to support complex cognition and manipulation tasks on demand.
39,soylent-uist2010.,0.00010862657654797658,39,"This process prevents errant crowd workers from contributing too much, too little, or introducing errors into the document."
80,soylent-uist2010.,0.00010849074897123501,80,Artificial Intelligence for Word Processing Automatic proofreading has a long history of research [14] and has seen successful deployment in word processors.
149,soylent-uist2010.,0.00010782663594000041,149,"Over the past year, we have performed and documented dozens of experiments on Mechanical Turk.5 For this project alone, we have interacted with 8809 Turkers across 2256 different tasks."
249,soylent-uist2010.,0.00010766773630166426,249,"We also measured wait time, the time between posting the task and the worker accepting the task, and work time, the time between acceptance and submission."
68,soylent-uist2010.,0.0001071876467904076,68,Our work also contributes the Find-Fix-Verify pattern to improve the quality of such proofreading services.
303,soylent-uist2010.,0.00010691911302274093,303,The user can take advantage of this functionality by pushing the Shortn button again once the results come back.
419,soylent-uist2010.,0.00010365016350988299,419,"Finally, we believe that our research points the way toward integrating on-demand crowd work into other authoring interfaces, particularly in creative domains like image editing and programming."
326,soylent-uist2010.,0.00010325047333026305,326,Results Soylent's proofreading algorithm caught 33 of the 49 errors (67%).
365,soylent-uist2010.,0.00010067062976304442,365,"Say what's wrong, and what I can improve."
265,soylent-uist2010.,9.884975588647649e-05,265,In this paper we argue that it is possible and desirable to combine the easy input affordances of text with the powerful retrieval and visualization capabilities of graphical applications.
54,soylent-uist2010.,9.829094051383436e-05,54,HelpMeOut [9] collects debugging traces and applies others' error solutions to help fix code.
116,soylent-uist2010.,9.80218974291347e-05,116,"To use Crowdproof, the user highlights a section of text and presses the proofreading button in the Soylent ribbon tab."
16,soylent-uist2010.,9.792319178814068e-05,16,"To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee."
38,soylent-uist2010.,9.787924500415102e-05,38,"Rather than ask a single crowd worker to read and edit an entire paragraph, for example, Find-FixVerify recruits one set of workers to find candidate areas for improvement, then collects a set of candidate improvements, and finally filters out incorrect candidates."
118,soylent-uist2010.,9.73212081589736e-05,118,"(Because Crowdproof costs money, it does not issue requests unless commanded.)"
247,soylent-uist2010.,9.515106648905203e-05,247,"To be slightly generous while matching going rates on Mechanical Turk, we paid $0.08 per Find, $0.05 per Fix, and $0.04 per Verify."
259,soylent-uist2010.,9.490329102845863e-05,259,"While wait time is important given the current Mechanical Turk, it is important to remember that the service will continue to grow."
10,soylent-uist2010.,9.480775042902678e-05,10,"Writing is difficult: even experts routinely make style, grammar and spelling mistakes."
418,soylent-uist2010.,9.409058839082718e-05,418,Second are new techniques for optimizing crowd-programmed algorithms to reduce wait time and cost.
144,soylent-uist2010.,9.393332584295422e-05,144,The Human Macro is an end-user programming interface for automating document manipulations.
229,soylent-uist2010.,9.362011769553646e-05,229,"In the Verify stage, five Turkers see a list of all the rewrites where each rewrite has been annotated using color and strikethroughs to highlight its differences from the original."
329,soylent-uist2010.,9.359475370729342e-05,329,"Word and Soylent tended to identify different errors, rather than both focusing on the easy and obvious mistakes."
283,soylent-uist2010.,9.311547910328954e-05,283,"For example, with the Blog input, Shortn was able to remove several words and phrases without changing the meaning of the sentence."
294,soylent-uist2010.,9.08664587768726e-05,294,"These Turkers could not predict that their cuts would not match, one cutting the parenthetical and the other cutting the main phrase."
61,soylent-uist2010.,9.00710656424053e-05,61,ChaCha2 recruits humans to do search engine queries for users who are mobile; Amazon Remembers uses Mechanical Turk to find products that match a photo taken by the user on a phone; Sala et al.
5,soylent-uist2010.,8.99197329999879e-05,5,"Evaluation studies demonstrate the feasibility of crowdsourced editing and investigate questions of reliability, cost, wait time, and work time for edits."
397,soylent-uist2010.,8.949529001256451e-05,397,"While paymentper-edit may restrict deployment to commercial contexts, it remains an open question whether the gains in productivity for the author are justified by the expense."
171,soylent-uist2010.,8.930728654377162e-05,171,Equally problematic as Lazy Turkers are Eager Beavers.
41,soylent-uist2010.,8.792078733677045e-05,41,Such work has generally aggregated previous crowd interactions rather than recruited an ondemand workforce for new requests.
212,soylent-uist2010.,8.75692130648531e-05,212,Independent agreement among Verify workers can help certify an edit as good or bad.
359,soylent-uist2010.,8.749710104893893e-05,359,"The average command saw an 88% intention success rate (max = 100%, min = 60%)."
311,soylent-uist2010.,8.74626130098477e-05,311,"Massesnis only canThe masses only can use the software developed by software companies, unless they know how to write programs."
86,soylent-uist2010.,8.550181519240141e-05,86,"for Word — for example, the common (but useless) Microsoft Word feedback, ""Fragment; consider revising."""
40,soylent-uist2010.,8.506190351909027e-05,40,"Soylent is influenced by prior work on crowdsourced interfaces (e.g., [1, 9, 24])."
404,soylent-uist2010.,8.414907642873004e-05,404,"We believe not: the Mechanical Turk worker contract explicitly states that it is workfor-hire, so results belong to the requester."
289,soylent-uist2010.,8.369980787392706e-05,289,"For example, it may be inappropriate to remove the academic signaling phrase ""In this paper we argue that..."" from an introduction."
379,soylent-uist2010.,8.330534910783172e-05,379,an image and proof that the image is Creative Commonslicensed.
190,soylent-uist2010.,8.263807831099257e-05,190,Any single Turker may produce a noisy result (e.g. Lazy Turkers might prefer errors near the beginning of a paragraph).
196,soylent-uist2010.,8.207976497942582e-05,196,The worker can see the entire paragraph but only edit the text directly containing the patch.
92,soylent-uist2010.,8.189598884200677e-05,92,Other work has considered naturallanguage-like programming syntax (e.g. [17]).
135,soylent-uist2010.,8.007867290871218e-05,135,"The form dialog is split in two mirrored pieces: a task entry form on the left, and a preview of what the Turker will see on the right."
273,soylent-uist2010.,7.955491309985518e-05,273,the future the worker population will be large enough to consume any task as soon as it is posted.
181,soylent-uist2010.,7.932435983093455e-05,181,Such errors are compounded if the output of one Turker is used as input for other Turkers.
103,soylent-uist2010.,7.925860700197518e-05,103,On the left is the original paragraph; on the right is the proposed revision.
109,soylent-uist2010.,7.917958282632753e-05,109,"Shortn typically can remove up to 15–30% of a paragraph in a single pass, and up to ~50% with multiple iterations."
248,soylent-uist2010.,7.875956362113357e-05,248,Each resulting paragraph had many possible variations depending on the number of shortened alternatives that passed the Verify stage – we chose the shortest possible version for analysis and compared its length to the original paragraph.
165,soylent-uist2010.,7.56901572458446e-05,165,"There are many themes that are present most of the way through such as sacrifice, friendship and comradeship."
308,soylent-uist2010.,7.5501375249587e-05,308,"It is no wondering that advertisings are is bad for companyies in America, Chicago and Germany."
323,soylent-uist2010.,7.46144141885452e-05,323,"Crowdproof on the inputs using a 20-minute stage timeout, with prices $0.06 for Find, $0.08 for Fix, and $0.04 for Verify."
293,soylent-uist2010.,7.456967432517558e-05,293,"Parallelism was another source of error: for example, in Highly Technical Writing (Table I), the two cuts were from two different patches, and thus handled by separate Turkers."
205,soylent-uist2010.,7.428060780512169e-05,205,"Lazy Turkers will always choose the easiest error to fix, so combining Find and Fix will result in poor coverage."
320,soylent-uist2010.,7.300759170902893e-05,320,"When we enter text, each (pen or key) stroke is being used to record the actual information we care about---; none is wasted on application navigation or configuration."
20,soylent-uist2010.,7.29691528249532e-05,20,Writing is no exception [7]: we commonly recruit friends and colleagues to help us shape and polish our writing.
218,soylent-uist2010.,7.279880810528994e-05,218,"To provide the user with near-continuous control of paragraph length, Shortn should produce many alternative rewrites without changing the meaning of the original text or introduce7 7 Word's grammar checker, eight authors and six reviewers did not catch the error in this sentence."
163,soylent-uist2010.,7.262046710820869e-05,163,This theme occurs during many circumstances but is not present from start to finish.
401,soylent-uist2010.,7.198790990514681e-05,401,"Rather than a binary opposition, a continuum of privacy and exposure options exists."
412,soylent-uist2010.,7.156498759286478e-05,412,Soylent is an example of a new kind of interactive user interface in which the end user has direct access to a crowd of workers for assistance with tasks that require human attention and common sense.
85,soylent-uist2010.,7.113999163266271e-05,85,"Tick marks represent possible lengths, and the blue background bounds the possible lengths."
408,soylent-uist2010.,6.869262870168313e-05,408,"We agree that some tasks, like fleshing out a related work section in an academic paper based on bullet points, are much more difficult to achieve on today's Mechanical Turk."
271,soylent-uist2010.,6.852996011730283e-05,271,Table I. Our evaluation run of Shortn produced revisions between 78% – 90% of the original paragraph length on a single run.
53,soylent-uist2010.,6.809735350543633e-05,53,Several systems power novel interactions with the wisdom of crowds.
256,soylent-uist2010.,6.799424591008574e-05,256,"Turkers merged sentences when patches spanned sentence boundaries (Table I, Classic UIST), and occasionally cut whole phrases or sentences."
387,soylent-uist2010.,6.74388647894375e-05,387,"DISCUSSION This section reviews some fundamental questions about the nature of paid, crowd-powered interfaces as embodied in Soylent."
319,soylent-uist2010.,6.739118543919176e-05,319,6 / 4 / 3 $3.30 53 workers 96 min Many of these problems vanish if we turn to a much older recording technology---text.
304,soylent-uist2010.,6.727308937115595e-05,304,"Crowdproof Evaluation To evaluate Crowdproof, we obtained a set of five input texts in need of proofreading (Table II)."
276,soylent-uist2010.,6.709499575663358e-05,276,"This process reveals that the median shortening took 118 seconds of work time, or just under two minutes, when summed across all three stages (Q1 = 60 seconds, Q3 = 3.6 minutes)."
81,soylent-uist2010.,6.685798871330917e-05,81,"However, Microsoft Word's spell checker frequently suffers from false positives, particularly with proper nouns and unusual names."
29,soylent-uist2010.,6.673095049336553e-05,29,"2) Crowdproof, a human-powered spelling and grammar checker that finds problems Word misses, explains the problems, and suggests fixes."
228,soylent-uist2010.,6.653944728896022e-05,228,"If it can be cut, we introduce the empty string as a rewrite."
235,soylent-uist2010.,6.535465945489705e-05,235,"When the user specifies a desired maximum length, Shortn searches for the longest combination of rewrites subject to the length constraint."
13,soylent-uist2010.,6.475683039752766e-05,13,"Good user interfaces aid these tasks; good artificial intelligence helps as well, but it is clear that we have far to go."
166,soylent-uist2010.,6.450734508689493e-05,166,"But in my opinion there is only one theme that is present from beginning to end, this theme is pursuit of dreams."
11,soylent-uist2010.,6.403166480595246e-05,11,"Then, when a writer makes high-level decisions like changing a passage from past to present tense or fleshing out citation sketches into a true references section, she is faced with executing daunting numbers of nontrivial tasks across the entire document."
332,soylent-uist2010.,6.294256309047341e-05,332,"Using the Verify stage to choose the best textual replacement, Soylent fixed 29 of the 33 errors it flagged (88%)."
279,soylent-uist2010.,6.281118839979172e-05,279,"This cost split into $0.55 to identify an average of two patches, then $0.48 to generate alternatives and $0.38 to filter results for each of those patches."
94,soylent-uist2010.,6.23284067842178e-05,94,Shortn: Text Shortening Some authors struggle to remain within length limits on papers and spend the last hours of the writing process tweaking paragraphs to shave a few lines.
48,soylent-uist2010.,6.219388887984678e-05,48,Crowdsourcing Gathering data to train algorithms is a common use of crowdsourcing.
339,soylent-uist2010.,6.188844417920336e-05,339,"There were also stylistic opinions that the original author might not have agreed with: in the Draft UIST example in Table II, the author clearly had a penchant for triple dashes that the Turkers did not appreciate."
47,soylent-uist2010.,6.1625505622942e-05,47,"RELATED WORK Soylent is related to work in two areas: crowdsourcing systems, and artificial intelligence for word processing."
219,soylent-uist2010.,6.116183067206293e-05,219,"Crowdproof later did, and correctly suggested that ""introduce"" should be ""introducing""."
191,soylent-uist2010.,6.115542055340484e-05,191,The Find stage aggregates independent opinions to find the most consistently cited problems: multiple independent agreement is typically a strong signal that a crowd is correct.
201,soylent-uist2010.,6.11473951721564e-05,201,"We either ask Turkers to vote on the best option (when like Crowdproof) or to flag poor suggestions (when the interface requires as many options as possible, like Shortn)."
44,soylent-uist2010.,6.076638965168968e-05,44,"In the rest of this paper, we review related work in crowdsourced interfaces and text editing."
230,soylent-uist2010.,6.072028918424621e-05,230,"Each Turker selects at least one rewrite that has significant spelling, grammar, or style problems, and at least one rewrite that significantly changes the meaning of the original sentence."
369,soylent-uist2010.,6.040635344106704e-05,369,"Admin: ""Please complete the addresses below informtion needed as in example below. [...]"""
269,soylent-uist2010.,6.0180511354701594e-05,269,Check out our new page: [...] $4.84 188 workers 132 – 489 min Figure 3 shows the pseudocode that implements this design for Lookup.
324,soylent-uist2010.,5.952327774139121e-05,324,"We measured the errors that Crowdproof caught, that Crowdproof fixed, and that Word caught."
12,soylent-uist2010.,5.943495125393383e-05,12,"Finally, when the document is a half-page over length, interactive software provides little support to help us trim those last few paragraphs."
317,soylent-uist2010.,5.848674481967464e-05,317,"Accorinding to hHindu believesfs in Ramayanaya King Ravana used ""Dandu Monara"" for abduct queen Seetha from Rama."
338,soylent-uist2010.,5.8115609135711566e-05,338,"A second problem was a lack of domain knowledge: in the ESL example in Table II, Turkers did not know what a GUI was, so they could not know that the author intended ""GUIs"" instead of ""GUI""."
180,soylent-uist2010.,5.792718366137706e-05,180,"For example, when proofreading paragraphs about the novel Of Mice and Men, Turkers variously changed the title to just Of Mice, replaced existing grammar errors with new errors of their own, and changed the text to state that Of Mice and Men is a movie rather than a novel."
280,soylent-uist2010.,5.7588469644542783e-05,280,"Were we instead to use a $0.01 pay rate for these tasks, the process would cost $0.30 per paragraph."
206,soylent-uist2010.,5.734763908549212e-05,206,"By splitting Find from Fix, we can direct Lazy Turkers to propose a fix to patches that they might otherwise ignore."
159,soylent-uist2010.,5.7253728300565854e-05,159,"We might characterize two useful personas at the ends of the effort spectrum, the Lazy Turker and the Eager Beaver."
161,soylent-uist2010.,5.708006210625172e-05,161,"For example, when asked to proofread the following error-filled paragraph from a high school essay site,6 a Lazy Turker inserted only a single character to correct a spelling mistake."
343,soylent-uist2010.,5.5746142606949434e-05,343,"It cost more money to run per paragraph (μ=$3.40, σ=$2.13) because it identified far more patches per paragraph: we chose paragraphs in dire need of proofreading."
153,soylent-uist2010.,5.573492671828717e-05,153,"In our experiments, it is evident that many of the raw results that Turkers produce on such tasks are unsatisfactory."
84,soylent-uist2010.,5.548435728996992e-05,84,Red text indicates locations where cuts or rewrites have occurred.
108,soylent-uist2010.,5.5326174333458766e-05,108,These areas may differ from one slider position to the next: the cuts are not monotonic in this sense.
395,soylent-uist2010.,5.5142580094980076e-05,395,One might therefore argue that interface outsourcing is too expensive to be practical.
260,soylent-uist2010.,5.460339889395982e-05,260,"Assuming that the number of work tasks does not increase equivalently, wait times will drop."
287,soylent-uist2010.,5.419528315542266e-05,287,"While Turkers tended to stay away from cutting material they did not understand, they still occasionally flagged such patches."
90,soylent-uist2010.,5.408320066635497e-05,90,The Human Macro is related to AI techniques for end-user programming.
355,soylent-uist2010.,5.394307299866341e-05,355,We coded results using two quality metrics: intention (did the Turker understand the prompt and make a good faith effort?)
175,soylent-uist2010.,5.380332368076779e-05,175,Eager Beavers may also leave extra comments in the document or reformat paragraphs.
52,soylent-uist2010.,5.344436794985086e-05,52,"However, Soylent's output may be used to train future AIs."
169,soylent-uist2010.,5.3320643928600475e-05,169,"attacked the problem of 5 http://groups.csail.mit.edu/uid/deneme/ 6 http://www.essay.org/school/english/ofmiceandmen.txt Lazy Turkers in crowdsourced user studies [12] by adding clearly verifiable, quantitative questions (e.g., ""How many sections does the article have?"")"
30,soylent-uist2010.,5.299969416228123e-05,30,"3) The Human Macro, an interface for offloading arbitrary word processing tasks such as formatting citations or finding appropriate figures."
300,soylent-uist2010.,5.2541679906426e-05,300,We experimented with feeding the shortest output from the Blog text back into the algorithm to see if it could continue shortening.
297,soylent-uist2010.,5.2177420002408326e-05,297,"The Verify step caught 19 of the errors (50% of 37) while also removing 15 grammatical sentences: its error rate was thus (18 false negatives + 15 false positives) / 137 = 26.1%, again near 30%."
360,soylent-uist2010.,5.182854874874465e-05,360,"Typical intention errors occurred when the prompt contained two requirements: for example, the Figure task asked both for Task Tense $0.10 1 paragraph Figure $0.20 1 paragraph Quality CS: 100% intention, (20% accuracy) Admin: 100% (40%) Author: 100% (60%) CS: 75% (75%) Admin: 75% (75%) Author: 60% (60%) Opinions $0.15 1 paragraph CS: 100% (100%) Admin: 100% (100%) Author: 100% (100%) Citation Gathering $0.40 3 citations CS: 75% (75%) Admin: 100% (100%) Author: 66% (40%) Example Request Admin: ""Please change text in document from past tense to present tense."""
97,soylent-uist2010.,5.16809850523714e-05,97,"Automatic summarization algorithms can provide useful summaries [18], but cannot easily determine what language to cut or shorten."
145,soylent-uist2010.,5.147019328433089e-05,145,The left half is the user's authoring interface; the right half is a preview of what the Turker will see.
330,soylent-uist2010.,5.124230301589705e-05,330,This result lends more support to Crowdproof's approach: it will waste relatively little money that an AI could have saved.
314,soylent-uist2010.,5.107459219289012e-05,314,"To protect yourself, use an open software offering, and self-host or go with hosting solution that uses open offering."
288,soylent-uist2010.,5.1067945605609566e-05,288,"As a result, Turkers sometimes made edits that were grammatically appropriate but stylistically incorrect."
113,soylent-uist2010.,5.041464100941084e-05,113,"Crowdproof aims to catch spelling, style and grammar errors that AI algorithms today cannot find or fix."
417,soylent-uist2010.,5.01715112477541e-05,417,"First are new crowddriven features for word processing, such as readability analysis, smart find-and-replace (so that renaming ""Michael"" to ""Michelle"" also changes ""he"" to ""she""), and figure or citation number checking."
227,soylent-uist2010.,4.928920679958537e-05,227,We now have a set of rewrites and votes on whether the text can be cut.
152,soylent-uist2010.,4.917116166325286e-05,152,"These tasks include shortening, proofreading, and user-requested changes such as address formatting."
9,soylent-uist2010.,4.8907179007073864e-05,9,It supports a deep cognitive activity – writing – and requires complicated manipulations.
21,soylent-uist2010.,4.861742854700424e-05,21,"But we cannot always rely on them: colleagues do not want to proofread every sentence we write, cut a few lines from every paragraph in a ten-page paper, or help us format thirty ACM-style references."
238,soylent-uist2010.,4.8400252126157284e-05,238,The Microsoft Word plug-in is written using Microsoft Visual Studio Tools for Office (VSTO) and the Windows Presentation Foundation (WPF).
35,soylent-uist2010.,4.770245141116902e-05,35,The fundamental technical contribution of this work is a crowd programming pattern called Find-Fix-Verify.
122,soylent-uist2010.,4.7151286707958207e-05,122,"When the crowd is finished, Soylent calls out the edited sections with a purple dashed underline."
198,soylent-uist2010.,4.6768036554567516e-05,198,"Even if 30% of work is bad, 3– 5 submissions are sufficient to produce viable alternatives."
376,soylent-uist2010.,4.629047907656059e-05,376,"[...] After reading I feel like there should be about five more sentences [...] @conference{ title={{Financial incentives and [...]}}, author={Mason, W. and Watts, D.J.}, booktitle={HCOMP '09}} to Max Marcus, 3416 colfax ave east, 80206 Max Marcus 3416 E Colfax Ave Denver, CO 80206 CS: 82% (82%) Admin: 98% (96%) Author: 91% (68%) List Processing $0.05 10 inputs Table III."
402,soylent-uist2010.,4.560774323181249e-05,402,"Soylent also raises questions over legal ownership of the resulting text, which is part-user and part-Turker generated."
121,soylent-uist2010.,4.49900035164319e-05,121,The drop-down explains the problem (blue title) and suggests fixes (gold selection).
363,soylent-uist2010.,4.460677519091405e-05,363,"As I do so, my eye catches something [...] CS: ""Pick out keywords from the paragrah like Yosemite, rock, half dome, park."
25,soylent-uist2010.,4.4599677494261414e-05,25,"They can also solve problems that artificial intelligence cannot, for example flagging writing errors that the word processor does not catch."
399,soylent-uist2010.,4.456662281882018e-05,399,Authors and their employers may not want such exposure if the document's content is confidential or otherwise sensitive.
296,soylent-uist2010.,4.3765587179223076e-05,296,"37 suggestions were ungrammatical, again supporting our rule of thumb that 30% of raw Turker edits will be noisy."
342,soylent-uist2010.,4.359384183771908e-05,342,"Similarly to Shortn, its wait time was 18 minutes (Median = 17.6, Q1 = 9.8, Q3 = 30.8)."
178,soylent-uist2010.,4.2785293771885335e-05,178,"Without clear guidelines, the Lazy Turker will choose the path that produces any signal and the Eager Beaver will produce too many signals."
59,soylent-uist2010.,4.200287366984412e-05,59,Having an 3 on-demand workforce also expands the realm of tasks we can support beyond those requiring traces or incentives.
281,soylent-uist2010.,4.112511669518426e-05,281,"Our experience is that paying less slows down the later parts of the process, but it does not impact quality [19] — it would be viable for shortening paragraphs under a loose deadline."
209,soylent-uist2010.,4.070067370776087e-05,209,"By splitting Find and Fix, we can map edits to patches and produce a much richer user interface—for example, the multiple options in Crowdproof's replacement dropdown."
374,soylent-uist2010.,3.92661131627392e-05,374,"Duncan and Watts [Duncan and watts HCOMP 09 anchoring] found that Turkers will do more work when you pay more, but that the quality is no higher."
226,soylent-uist2010.,3.900774390785955e-05,226,"Each agreed-upon patch moves on to the Fix stage, where five Turkers see it highlighted in the paragraph and are asked to shorten it, as well as determine if the patch can be cut entirely."
415,soylent-uist2010.,3.890811058226973e-05,415,"We evaluated Soylent with a range of editing tasks, finding and correcting 82% of grammar errors when combined with automatic checking, shortening text to approximately 85% of original length per iteration, and executing a variety of human macros successfully."
100,soylent-uist2010.,3.863791425828822e-05,100,The user selects the area of text that is too long—for example a paragraph or section—then presses the Shortn button in the Word's Soylent ribbon tab.
24,soylent-uist2010.,3.852352892863564e-05,24,"These workers perform tasks that the writer might not, such as scrupulously scanning for text to cut, or updating a list of addresses to include a zip code."
56,soylent-uist2010.,3.8331036193994805e-05,56,MySong [24] indexes a library of music chords to enable the user to build a chord progression by singing a melody line.
136,soylent-uist2010.,3.8163027056725696e-05,136,"The preview contextualizes the user's request, reminding the user he is writing something akin to a Help Wanted or Craigslist advertisement."
407,soylent-uist2010.,3.783665306400508e-05,407,A final concern is that anonymous workers may not have the necessary domain knowledge or enough shared context to usefully contribute.
255,soylent-uist2010.,3.5019766073673964e-05,255,"Typically, Shortn focused on unnecessarily wordy phrases like ""are going to have to"" (Table I, Blog)."
110,soylent-uist2010.,3.3693020668579265e-05,110,"The Shortn algorithm preserves meaning when possible, so it cuts unnecessary language or concept repetition."
